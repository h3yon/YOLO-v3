{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/object-detection-with-opencv-python-using-yolov3-481f02c6aa35\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo v3 알고리즘을 로드\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolov3.cfg\")\n",
    "\n",
    "classes = []\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "    # coco.names: 80 개의 클래스 이름\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.getUnconnectedOutLayers 및 \n",
    "# net.getLayerNames 를 사용하여 감지되는 개체를 정의하는 출력 레이어를 정의\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위 표본 표출, 난수 만듦\n",
    "colors= np.random.uniform(0,255,size=(len(classes),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 높이와 너비를 40 % 및 30 % 배율로 줄입니다. \n",
    "# 그리고 모든 값을 원본 이미지의 높이, 너비, 채널 변수에 저장합니다.\n",
    "img = cv2.imread(\"area.jpeg\")\n",
    "img = cv2.resize(img,None,fx=0.4,fy=0.3)\n",
    "height,width,channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Image\",img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blob: 특징 추출\n",
    "# cv2.dnn.blobFromImage 를 사용 하고 몇 가지 변수를 전달 하여 blob에서 개체를 감지\n",
    "blob = cv2.dnn.blobFromImage(img,0.00392,(416,416),(0,0,0),True,crop=False)\n",
    "\n",
    "# img 는 파일 이름, scalefactor 0.00392, blob에서 사용할 이미지 크기는 (416,416), \n",
    "# 레이어에서 평균 빼기 (0,0) 없음 , 0), \n",
    "\n",
    "# True 플래그를 설정 하면 OpenCV가 BGR을 사용하기 때문에 \n",
    "# 파란색을 빨간색으로 반전하지만 이미지에 RGB로 채널이 있음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 가지 다른 Blob이 어떻게 보이는지 살펴볼 수 있는 코드\n",
    "# for b in blob:\n",
    "#     for n,img_blob in enumerate(b):\n",
    "#         cv2.imshow(str(n),img_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.setInput(blob): blob을 네트워크에 전달한 다음, 이를 출력하고 계층에 전달\n",
    "net.setInput(blob)\n",
    "\n",
    "# outs 에는 위쪽, 왼쪽, 오른쪽, 아래쪽 위치, 클래스 이름과 같은 \n",
    "# 개체의 위치를 추출하는 데 필요한 모든 정보가 포함\n",
    "outs = net.forward(outputlayers)\n",
    "\n",
    "#print(outs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃을 화면에 정보를 표시하여,\n",
    "# 물체를 예측할 때 알고리즘이 얼마나 자신감이 있는지를 의미하는 신뢰도를 예측하고자 함\n",
    "\n",
    "\n",
    "class_ids=[]\n",
    "confidences=[]\n",
    "boxes=[]\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        # 신뢰도 예측을 위해 out을 반복 하고 각 out에 대한 모든 점수를 얻음\n",
    "        scores = detection[5:]\n",
    "        # 가장 높은 점수를 할당\n",
    "        # CLASS_ID의 점수를 전달하여 가장 높은 점수에 대한 신뢰도 계산함\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        # 신뢰 수준 임계값을 0.5로 할당한다. \n",
    "        # 0.5 이상이면 물체가 감지되었음을 의미.\n",
    "        if confidence > 0.5:\n",
    "            # center_x, center_y를 구하고, w 를 너비로, h 를 감지 된 물체의 높이로 설정\n",
    "            # 이전에 원본 이미지에서 저장 한 높이, 너비 변수를 사용\n",
    "            center_x= int(detection[0]*width)\n",
    "            center_y= int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "            \n",
    "        \n",
    "            # 물체가 감지되었다는 증거를 위해 물체 중앙에 두께 2의 원을 그림\n",
    "            #cv2.circle(img,(center_x,center_y),10,(0,255,0),2)\n",
    "            \n",
    "            # center_x, center_y, w, h 를 사용하여 \n",
    "            # 감지된 물체 주위에 사각형을 그림.\n",
    "            # class_id, 신뢰도 같은 정보 추가\n",
    "            x=int(center_x - w/2)\n",
    "            y=int(center_y - h/2)\n",
    "            #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            \n",
    "            boxes.append([x,y,w,h]) #put all rectangle areas\n",
    "            confidences.append(float(confidence)) #how confidence was that object detected and show that percentage\n",
    "            class_ids.append(class_id) #name of the object tha was detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 물체에 대해 사각형이 2개 이상 생기는 모습을 볼 수 있음.\n",
    "# NMS (Non-Max Suppression) 기능을 사용하여 이 현상을 없애고자 함.\n",
    "\n",
    "# 0.6 미만의 값을 가진 모든 상자를 제거하여 가장 좋은 것만 유지하도록 결정\n",
    "# indexes 변수는 감지 된 고유한 개체를 추적하여 동일한 물체를 여러번 감지하지 않음.\n",
    "indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.4,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 상자 에 대해 아래 loop 반복을 사용하여 \n",
    "# 상자가 색인에 나타나면 사각형을 그리고 색상을 지정하고 클래스 이름의 텍스트를 그 위에 놓습니다.\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x,y,w,h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "        cv2.putText(img,label,(x,y+30),font,1,(255,255,255),2)\n",
    "            \n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ->자동차, 사람 및 오토바이를 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
